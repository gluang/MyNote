<h1 align="center">目录</h1>

* [1. 线程池 1](#1-线程池-1)
* [2. 线程池 2](#2-线程池-2)
* [3. 线程池 3（未测试）](#3-线程池-3未测试)

---

# 1. 线程池 1

【题目】请编写一个简单的线程池，提供如下功能：

```cpp
ThreadPool p(4); // 指定四个工作线程

// 将任务在池中入队，并返回一个 std::future
auto f = pool.enqueue([](int life) {
    return meaning;
}, 42);

// 从 future 中获得执行结果
std::cout << f.get() << std::endl;
```

【参考资料】

```cpp
// exercises/7/7.1/thread_pool.hpp

#ifndef THREAD_POOL_H
#define THREAD_POOL_H

#include <vector>               // std::vector
#include <queue>                // std::queue
#include <memory>               // std::make_shared

#include <thread>               // std::thread
#include <mutex>                // std::mutex, std::unique_lock
#include <condition_variable>   // std::condition_variable
#include <future>               // std::future, std::packaged_task

#include <functional>           // std::function, std::bind
#include <stdexcept>            // std::runtime_error
#include <utility>              // std::move, std::forward

class ThreadPool {
public:
    
    // initialize the number of concurrency threads
    ThreadPool(size_t);
    
    // enqueue new thread task
    template<class F, class... Args>
    decltype(auto) enqueue(F&& f, Args&&... args);

    // destroy thread pool and all created threads
    ~ThreadPool();
private:
    
    // thread list, stores all threads
    std::vector< std::thread > workers;
    // queue task, the type of queue elements are functions with void return type
    std::queue< std::function<void()> > tasks;
    
    // for synchonization
    std::mutex queue_mutex;
    // std::condition_variable is a new feature from c++11,
    // it's a synchronization primitives. it can be used 
    // to block a thread or threads at the same time until
    // all of them modified condition_variable.
    std::condition_variable condition;
    bool stop;
};
 
// constructor initialize a fixed size of worker
inline ThreadPool::ThreadPool(size_t threads): stop(false) {
    // initialize worker
    for(size_t i = 0;i<threads;++i)
        // std::vector::emplace_back :
        //    append to the end of vector container
        //    this element will be constructed at the end of container, without copy and move behavior
        workers.emplace_back([this] { // the lambda express capture this, i.e. the instance of thread pool
                // avoid fake awake
                for(;;) {
                    // define function task container, return type is void
                    std::function<void()> task;

                    // critical section
                    {
                        // get mutex
                        std::unique_lock<std::mutex> lock(this->queue_mutex);
                        
                        // block current thread
                        this->condition.wait(lock,
                            [this]{ return this->stop || !this->tasks.empty(); });
                        
                        // return if queue empty and task finished
                        if(this->stop && this->tasks.empty())
                            return;
                        
                        // otherwise execute the first element of queue
                        task = std::move(this->tasks.front());
                        this->tasks.pop();
                    }
                    
                    // execution
                    task();
                }
            }
        );
}

// Enqueue a new thread
// use variadic templates and tail return type 
template<class F, class... Args>
decltype(auto) ThreadPool::enqueue(F&& f, Args&&... args) {
    // deduce return type
    using return_type = typename std::result_of<F(Args...)>::type;

    // fetch task
    auto task = std::make_shared<std::packaged_task<return_type()>>(
        std::bind(std::forward<F>(f), std::forward<Args>(args)...)
    );

    std::future<return_type> res = task->get_future();

    // critical section
    {
        std::unique_lock<std::mutex> lock(queue_mutex);

        // avoid add new thread if theadpool is destroyed
        if(stop)
            throw std::runtime_error("enqueue on stopped ThreadPool");

        // add thread to queue
        tasks.emplace([task]{ (*task)(); });
    }

    // notify a wait thread
    condition.notify_one();
    return res;
}

// destroy everything
inline ThreadPool::~ThreadPool()
{
    // critical section
    {
        std::unique_lock<std::mutex> lock(queue_mutex);
        stop = true;
    }

    // wake up all threads
    condition.notify_all();

    // let all processes into synchronous execution, use c++11 new for-loop: for(value:values)
    for(std::thread &worker: workers)
        worker.join();
}

#endif
```

```cpp
// exercises/7/7.1/main.cpp

#include <iostream> // std::cout, std::endl

#include <vector>   // std::vector
#include <string>   // std::string
#include <future>   // std::future
#include <thread>   // std::this_thread::sleep_for
#include <chrono>   // std::chrono::seconds

#include "thread_pool.hpp"

int main()
{
    // create a thread pool with max. 4 concurrency threads
    ThreadPool pool(4);
    // create execution results list
    std::vector< std::future<std::string> > results;

    // start eight thread task
    for(int i = 0; i < 8; ++i) {
        // add all task to result list
        results.emplace_back(
            // ass print task to thread pool
            pool.enqueue([i] {
                std::cout << "hello " << i << std::endl;
                // wait a sec when the previous line is out
                std::this_thread::sleep_for(std::chrono::seconds(1));
                // keep output and return the status of execution
                std::cout << "world " << i << std::endl;
                return std::string("---thread ") + std::to_string(i) + std::string(" finished.---");
            })
        );
    }

    // outputs
    for(auto && result: results)
        std::cout << result.get() << ' ';
    std::cout << std::endl;

    return 0;
}
```


# 2. 线程池 2
* threadpool.h

```cpp
#pragma once
#ifndef THREAD_POOL_H
#define THREAD_POOL_H

#include <vector>
#include <queue>
#include <thread>
#include <atomic>
#include <condition_variable>
#include <future>
#include <functional>
#include <stdexcept>

namespace std
{
#define  MAX_THREAD_NUM 256

	//线程池,可以提交变参函数或拉姆达表达式的匿名函数执行,可以获取执行返回值
	//不支持类成员函数, 支持类静态成员函数或全局函数,Opteron()函数等
	class threadpool
	{
		using Task = std::function<void()>;	
		std::vector<std::thread>	pool;		// 线程池	
		std::queue<Task>			tasks;		// 任务队列	
		std::mutex					m_lock;		// 同步
		std::condition_variable		cv_task;	// 条件阻塞
		std::atomic<bool>			stoped;		// 是否关闭提交
		std::atomic<int>			idlThrNum;	// 空闲线程数量

	public:
		inline threadpool(unsigned short size = 4) :stoped{ false }
		{
			idlThrNum = size < 1 ? 1 : size;
			for (size = 0; size < idlThrNum; ++size)
			{   //初始化线程数量
				pool.emplace_back(
					[this]
				{ // 工作线程函数
					while (!this->stoped)
					{
						std::function<void()> task;
						{   // 获取一个待执行的 task
							std::unique_lock<std::mutex> lock{ this->m_lock };// unique_lock 相比 lock_guard 的好处是：可以随时 unlock() 和 lock()
							this->cv_task.wait(lock,
								[this] {
								return this->stoped.load() || !this->tasks.empty();
							}
							); // wait 直到有 task
							if (this->stoped && this->tasks.empty())
								return;
							task = std::move(this->tasks.front()); // 取一个 task
							this->tasks.pop();
						}
						idlThrNum--;
						task();
						idlThrNum++;
					}
				}
				);
			}
		}
		inline ~threadpool()
		{
			stoped.store(true);
			cv_task.notify_all(); // 唤醒所有线程执行
			for (std::thread& thread : pool) {
				//thread.detach(); // 让线程“自生自灭”
				if (thread.joinable())
					thread.join(); // 等待任务结束， 前提：线程一定会执行完
			}
		}

	public:
		// 提交一个任务
		// 调用.get()获取返回值会等待任务执行完,获取返回值
		// 有两种方法可以实现调用类成员，
		// 一种是使用   bind： .commit(std::bind(&Dog::sayHello, &dog));
		// 一种是用 mem_fn： .commit(std::mem_fn(&Dog::sayHello), &dog)
		template<class F, class... Args>
		auto commit(F&& f, Args&&... args) ->std::future<decltype(f(args...))>
		{
			if (stoped.load())    // stop == true ??
				throw std::runtime_error("commit on ThreadPool is stopped.");

			using RetType = decltype(f(args...)); // typename std::result_of<F(Args...)>::type, 函数 f 的返回值类型
			auto task = std::make_shared<std::packaged_task<RetType()> >(
				std::bind(std::forward<F>(f), std::forward<Args>(args)...)
				);    // wtf !
			std::future<RetType> future = task->get_future();
			{    // 添加任务到队列
				std::lock_guard<std::mutex> lock{ m_lock };//对当前块的语句加锁  lock_guard 是 mutex 的 stack 封装类，构造的时候 lock()，析构的时候 unlock()
				tasks.emplace(
					[task]()
				{ // push(Task{...})
					(*task)();
				}
				);
			}
			cv_task.notify_one(); // 唤醒一个线程执行

			return future;
		}

		//空闲线程数量
		int idlCount() { return idlThrNum; }

	};

}

#endif
```

* main.cpp

```cpp
#include "threadpool.h"
#include <iostream>

void fun1(int slp)
{
	printf("  hello, fun1 !  %d\n", std::this_thread::get_id());
	if (slp > 0) {
		printf(" ======= fun1 sleep %d  =========  %d\n", slp, std::this_thread::get_id());
		std::this_thread::sleep_for(std::chrono::milliseconds(slp));
	}
}

struct gfun {
	int operator()(int n) {
		printf("%d  hello, gfun !  %d\n", n, std::this_thread::get_id());
		return 42;
	}
};

class A {
public:
	static int Afun(int n = 0) {   //函数必须是 static 的才能直接使用线程池
		std::cout << n << "  hello, Afun !  " << std::this_thread::get_id() << std::endl;
		return n;
	}

	static std::string Bfun(int n, std::string str, char c) {
		std::cout << n << "  hello, Bfun !  " << str.c_str() << "  " << (int)c << "  " << std::this_thread::get_id() << std::endl;
		return str;
	}
};

int main()
try {
	std::threadpool executor{ 50 };
	A a;
	std::future<void> ff = executor.commit(fun1, 0);
	std::future<int> fg = executor.commit(gfun{}, 0);
	std::future<int> gg = executor.commit(a.Afun, 9999); //IDE提示错误,但可以编译运行
	std::future<std::string> gh = executor.commit(A::Bfun, 9998, "mult args", 123);
	std::future<std::string> fh = executor.commit([]()->std::string { std::cout << "hello, fh !  " << std::this_thread::get_id() << std::endl; return "hello,fh ret !"; });

	std::cout << " =======  sleep ========= " << std::this_thread::get_id() << std::endl;
	std::this_thread::sleep_for(std::chrono::microseconds(900));

	for (int i = 0; i < 50; i++) {
		executor.commit(fun1, i * 100);
	}
	std::cout << " =======  commit all ========= " << std::this_thread::get_id() << " idlsize=" << executor.idlCount() << std::endl;

	std::cout << " =======  sleep ========= " << std::this_thread::get_id() << std::endl;
	std::this_thread::sleep_for(std::chrono::seconds(3));

	ff.get(); //调用.get()获取返回值会等待线程执行完,获取返回值
	std::cout << fg.get() << "  " << fh.get().c_str() << "  " << std::this_thread::get_id() << std::endl;

	std::cout << " =======  sleep ========= " << std::this_thread::get_id() << std::endl;
	std::this_thread::sleep_for(std::chrono::seconds(3));

	std::cout << " =======  fun1,55 ========= " << std::this_thread::get_id() << std::endl;
	executor.commit(fun1, 55).get();    //调用.get()获取返回值会等待线程执行完

	std::cout << "end... " << std::this_thread::get_id() << std::endl;


	std::threadpool pool(4);
	std::vector< std::future<int> > results;

	for (int i = 0; i < 8; ++i) {
		results.emplace_back(
			pool.commit([i] {
			std::cout << "hello " << i << std::endl;
			std::this_thread::sleep_for(std::chrono::seconds(1));
			std::cout << "world " << i << std::endl;
			return i*i;
		})
			);
	}
	std::cout << " =======  commit all2 ========= " << std::this_thread::get_id() << std::endl;

	for (auto && result : results)
		std::cout << result.get() << ' ';
	std::cout << std::endl;
	return 0;
}
catch (std::exception& e) {
	std::cout << "some unhappy happened...  " << std::this_thread::get_id() << e.what() << std::endl;
}
```


# 3. 线程池 3（未测试）

```cpp
#include <mutex>
#include <condition_variable>
#include <functional>
#include <queue>
#include <thread>

class fixed_thread_pool {
public:
	explicit fixed_thread_pool(size_t thread_count)
		: data_(std::make_shared<data>()) {
		for (size_t i = 0; i < thread_count; ++i) {
			std::thread([data = data_] {
				std::unique_lock<std::mutex> lk(data->mtx_);
				for (;;) {
					if (!data->tasks_.empty()) {
						auto current = std::move(data->tasks_.front());
						data->tasks_.pop();
						lk.unlock();
						current();
						lk.lock();
					}
					else if (data->is_shutdown_) {
						break;
					}
					else {
						data->cond_.wait(lk);
					}
				}
			}).detach();
		}
	}

	fixed_thread_pool() = default;
	fixed_thread_pool(fixed_thread_pool&&) = default;

	~fixed_thread_pool() {
		if ((bool)data_) {
			{
				std::lock_guard<std::mutex> lk(data_->mtx_);
				data_->is_shutdown_ = true;
			}
			data_->cond_.notify_all();
		}
	}

	template <class F>
	void execute(F&& task) {
		{
			std::lock_guard<std::mutex> lk(data_->mtx_);
			data_->tasks_.emplace(std::forward<F>(task));
		}
		data_->cond_.notify_one();
	}

private:
	struct data {
		std::mutex mtx_;
		std::condition_variable cond_;
		bool is_shutdown_ = false;
		std::queue<std::function<void()>> tasks_;
	};
	std::shared_ptr<data> data_;
};

int main() {

    fixed_thread_pool pool(3);

    for (int i = 0; i < 8; ++i) {
        pool.execute([ i ] {
            std::cout << "hello " << i << std::endl;
            // wait a sec when the previous line is out
            std::this_thread::sleep_for(std::chrono::milliseconds(10));
            // keep output and return the status of execution
            std::cout << "world " << i << std::endl;
            std::cout << std::string("---thread：") << std::this_thread::get_id() << std::endl;
        });
    }

    std::this_thread::sleep_for(std::chrono::seconds(2));

    return 0;
}
```

```
hello hello 2
0
hello 1
world 2
---thread：140117221295872
hello 3
world 0
---thread：world 140117212903168
hello 4
1
---thread：140117229688576
hello 5
world 3
---thread：140117221295872
hello 6
world 4
---thread：140117212903168
hello 7
world 5
---thread：140117229688576
world 6
---thread：140117221295872
world 7
---thread：140117212903168
```